## Global settings ##

# instance id's distinguish stats of multiple relays.
# do not run multiple relays with the same instance id.
# supported variables:
#  ${HOST} : hostname
instance = "${HOST}"
max_procs = 2

admin_addr = "0.0.0.0:2004"
http_addr = "0.0.0.0:8081"
#spool_dir = "/var/spool/carbon-relay-ng"
spool_dir = "spool"
#pid_file = "/var/run/carbon-relay-ng.pid"
pid_file = "carbon-relay-ng.pid"

## Logging ##
# one of critical error warning notice info debug
# see docs/logging.md for level descriptions
log_level = "notice"

## Validation of inputs ##
# Metric name validation strictness for legacy metrics. Valid values are:
# strict - Block anything that can upset graphite: valid characters are [A-Za-z0-9_-.]; consecutive dots are not allowed
# medium - Valid characters are ASCII; no embedded NULLs
# none   - No validation is performed
validation_level_legacy = "medium"
# Metric validation for carbon2.0 (metrics2.0) metrics.
# Metrics that contain = or _is_ are assumed carbon2.0.
# Valid values are:
# medium - checks for unit and mtype tag, presence of another tag, and constency (use = or _is_, not both)
# none   - No validation is performed
validation_level_m20 = "medium"

# you can also validate that each series has increasing timestamps
validate_order = false

# How long to keep track of invalid metrics seen
# Useful time units are "s", "m", "h"
bad_metrics_max_age = "24h"

# Blacklist

blacklist = [
  'prefix collectd.localhost',
  'regex ^foo\..*\.cpu+'
]

## Inputs ##

### plaintext Carbon ###
listen_addr = "0.0.0.0:2003"

### Pickle Carbon ###
pickle_addr = "0.0.0.0:2013"

### AMQP ###
[amqp]
amqp_enabled = false
amqp_host = "localhost"
amqp_port = 5672
amqp_user = "guest"
amqp_password = "guest"
amqp_vhost = "/graphite"
amqp_exchange = "metrics"
amqp_queue = ""
amqp_key = "#"
amqp_durable = false
amqp_exclusive = true

# Aggregaters

[[aggregation]]
# aggregate timer metrics with sums
function = 'sum'
prefix = ''
substr = ''
regex = '^stats\.timers\.(app|proxy|static)[0-9]+\.requests\.(.*)'
format = 'stats.timers._sum_$1.requests.$2'
interval = 10
wait = 20

[[aggregation]]
# aggregate timer metrics with averages
function = 'avg'
prefix = ''
substr = 'requests'
regex = '^stats\.timers\.(app|proxy|static)[0-9]+\.requests\.(.*)'
format = 'stats.timers._avg_$1.requests.$2'
interval = 5
wait = 10

# Rewriters

[[rewriter]]
# rewrite all instances of testold to testnew
old = 'testold'
new = 'testnew'
max = -1

# Routes

[[route]]
# a plain carbon route that sends all data to the specified carbon (graphite) server
key = 'carbon-default'
type = 'sendAllMatch'
# prefix = ''
# substr = ''
# regex = ''
destinations = [
  '127.0.0.1:2003 spool=true pickle=false'
]

[[route]]
# all metrics with '=' in them are metrics2.0, send to carbon-tagger service
key = 'carbon-tagger'
type = 'sendAllMatch'
substr = '='
destinations = [
  '127.0.0.1:2006'
]

[[route]]
# send to the first carbon destination that matches the metric
key = 'analytics'
type = 'sendFirstMatch'
regex = '(Err/s|wait_time|logger)'
destinations = [
  'graphite.prod:2003 prefix=prod. spool=true pickle=true',
  'graphite.staging:2003 prefix=staging. spool=true pickle=true'
]

#[[route]]
# example route for https://grafana.com/cloud/metrics
#key = 'grafanaNet'
#type = 'grafanaNet'
#addr = 'your-base-url/metrics'
#apikey = 'your-grafana.net-api-key'
#schemasFile = 'examples/storage-schemas.conf'

[init]
# you can also put init commands here, in the same format as you'd use for the telnet interface
# (which is a bit tricky to use with its double spaces etc, so you're typically better off defining
# your setup via the sections above)
# here are some examples:
cmds = [
     # a plain carbon route that sends all data to the specified carbon (graphite) server (note the double space)
     #'addRoute sendAllMatch carbon-default  your-graphite-server:2003 spool=true pickle=false',

     # example route for https://grafana.com/cloud/metrics (note the double space)
     #'addRoute grafanaNet grafanaNet  your-base-url/metrics your-grafana.net-api-key /path/to/storage-schemas.conf',

     # ignore hosts that don't set their hostname properly via prefix match
     #'addBlack prefix collectd.localhost',

     # ignore foo.<anything>.cpu.... via regex match
     #'addBlack regex ^foo\..*\.cpu+',

     # aggregate timer metrics with sums
     #'addAgg sum regex=^stats\.timers\.(app|proxy|static)[0-9]+\.requests\.(.*) stats.timers._sum_$1.requests.$2 10 20',

     # aggregate timer metrics with averages
     #'addAgg avg regex=^stats\.timers\.(app|proxy|static)[0-9]+\.requests\.(.*) sub=requests stats.timers._avg_$1.requests.$2 5 10',

     # all metrics with '=' in them are metrics2.0, send to carbon-tagger service (note the double space)
     #'addRoute sendAllMatch carbon-tagger sub==  127.0.0.1:2006',

     # send to the first carbon destination that matches the metric (note the double spaces between destinations)
     #'addRoute sendFirstMatch analytics regex=(Err/s|wait_time|logger)  graphite.prod:2003 prefix=prod. spool=true pickle=true  graphite.staging:2003 prefix=staging. spool=true pickle=true'
]

## Instrumentation ##

[instrumentation]
# in addition to serving internal metrics via expvar, you can send them to graphite/carbon
# IMPORTANT: setting this to "" will disable flushing, and metrics will pile up and lead to OOM
# see https://github.com/graphite-ng/carbon-relay-ng/issues/50
# so for now you MUST send them somewhere. sorry.
# (Also, the interval here must correspond to your setting in storage-schemas.conf if you use grafana hosted metrics)
graphite_addr = "localhost:2003"
graphite_interval = 1000  # in ms
